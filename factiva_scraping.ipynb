{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d25c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException, UnexpectedAlertPresentException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pickle, json, time, os\n",
    "import regex as re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_searches():\n",
    "    \n",
    "    sources = ['rst=sfusat', 'rst=sfwsj', 'rst=sfnyt', 'rst=sfglob', '(rst=ftft or rst=ftcom)']\n",
    "    companies = ['fds=applc']\n",
    "\n",
    "    return [f'{source} and {company}' for source in sources for company in companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6ac322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_search(driver, wait, dates, year, search):\n",
    "    \n",
    "    print(year)\n",
    "    print(dates)\n",
    "\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class=\"pillNoMenu\"]'))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//select[@name=\"dr\"]'))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//option[@value=\"Custom\"]'))).click()\n",
    "    driver.find_element(By.ID, 'frm').send_keys('01')\n",
    "    driver.find_element(By.ID, 'frd').send_keys('01')\n",
    "    driver.find_element(By.ID, 'fry').send_keys(year)\n",
    "    driver.find_element(By.ID, 'tom').send_keys(dates[0])\n",
    "    driver.find_element(By.ID, 'tod').send_keys(dates[1])\n",
    "    driver.find_element(By.ID, 'toy').send_keys(year)\n",
    "    driver.find_element(By.XPATH, '//select[@name=\"isrd\"]').click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//option[@value=\"High\"]'))).click()\n",
    "    search_box = driver.find_element(By.XPATH, '//textarea[@name=\"ftx\"]')\n",
    "    search_box.send_keys(search)\n",
    "    search_box.send_keys(Keys.ENTER)\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//span[@data-channel=\"Dowjones\"]')))\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a011bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_info(soup, counter, year):\n",
    "    \n",
    "    article_links = []\n",
    "    map_dict = {\n",
    "        'January': '1',\n",
    "        'February': '1',\n",
    "        'March': '1',\n",
    "        'April': '2',\n",
    "        'May': '2',\n",
    "        'June': '2',\n",
    "        'July': '3',\n",
    "        'August': '3',\n",
    "        'September': '3',\n",
    "        'October': '4',\n",
    "        'November': '4',\n",
    "        'December': '4',\n",
    "    }\n",
    "    \n",
    "    for headline in soup.find_all('tr', {'class': 'headline'}):\n",
    "            \n",
    "        article_links.append(headline.find('a').get('href'))\n",
    "        sub_list = sum([subtitle.split(' ') for subtitle in headline.find('div').text.split(',') if len(re.findall('[0-9]+', subtitle)) > 0], [])\n",
    "        month = ''.join(set(sub_list) & set(map_dict.keys()))\n",
    "        counter[year][map_dict[month]] += 1\n",
    "        \n",
    "    return counter, article_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b6de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(eid_username, eid_password, search_function, first_login):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes three arguments:\n",
    "    \n",
    "    1. eid_username\n",
    "    \n",
    "        - Should be your UT EID username that you use to login to Canvas\n",
    "    \n",
    "    2. eid_password\n",
    "    \n",
    "        - Should be your password to login to Canvas\n",
    "        - I recommend you putting the password in a .env file and using the following format for the password argument:\n",
    "        os.getenv(\"password_variable_name\") where password variable name is a name you choose to define your password variable\n",
    "        inside of the .env folder.\n",
    "        \n",
    "    3. first_login\n",
    "    \n",
    "        - A boolean that is True if your browser has not yet logged into Factiva and False otherwise. Every time you\n",
    "        reopen the browser, you need to set this to True because closing the browser deletes some of your session cookies. Afterwards, you\n",
    "        may return to the main search page by setting this value to false and rerunning the function.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://guides.lib.utexas.edu/db/144'\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_experimental_option(\"debuggerAddress\", \"localhost:9222\")\n",
    "    driver = webdriver.Chrome(executable_path = \"C://Users//galon//cd_secure//chromedriver.exe\",options=option)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    driver.set_page_load_timeout(40)\n",
    "    driver.get(url)\n",
    "    \n",
    "    if first_login == True:\n",
    "\n",
    "        wait.until(EC.element_to_be_clickable((By.ID, 'username')))\n",
    "        driver.find_element(By.ID, 'username').send_keys(eid_username)\n",
    "        driver.find_element(By.ID, 'password').send_keys(eid_password)    \n",
    "        driver.find_element(By.XPATH, \"//input[@value='Sign in']\").click()\n",
    "        try:\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='trust-browser-button']\"))).click()\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print('Duo cookies still valid; proceeding to search page...')   \n",
    "    print(f'Starting at: {datetime.now()}\\n')\n",
    "    \n",
    "    for search in search_function:\n",
    "        \n",
    "        years = range(1995, 2021)\n",
    "        counter = {year: {'1': 0, '2': 0, '3': 0, '4': 0, 'duplicates': 0} for year in years}\n",
    "        for year in years:\n",
    "            \n",
    "            if year < 2020:\n",
    "                dates = ('12', '31')\n",
    "            else:\n",
    "                dates = ('06', '30')\n",
    "            enter_search(driver, wait, dates, year, search)\n",
    "\n",
    "            while year:\n",
    "                \n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                print(f'Soup found! {type(soup)}')\n",
    "                if \"No search results\" in soup.find('div', {'id': 'headlines'}).text:\n",
    "                    driver.get('https://guides.lib.utexas.edu/db/144')\n",
    "                    break\n",
    "                else:\n",
    "                    counter, article_links = get_page_info(soup, counter, year)\n",
    "                    try:\n",
    "                        counter['duplicates'] += int(soup.find('span', {'id': 'dedupSummary'}).text.split(':')[1].strip())\n",
    "                    except KeyError:\n",
    "                        print('No duplicates on this page')\n",
    "                    try:\n",
    "                        wait.until(EC.element_to_be_clickable((By.XPATH, '//a[@class=\"nextItem\"]'))).click()\n",
    "                        wait.until(EC.visibility_of_element_located((By.XPATH, '//img[@src=\"../img/listmanager/progress.gif\"]')))\n",
    "                        wait.until(EC.invisibility_of_element_located((By.XPATH, '//img[@src=\"../img/listmanager/progress.gif\"]')))\n",
    "                        time.sleep(3)\n",
    "                    except TimeoutException:\n",
    "                        driver.get('https://guides.lib.utexas.edu/db/144')\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dbc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galon\\AppData\\Local\\Temp\\ipykernel_17248\\2374334182.py:28: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"C://Users//galon//cd_secure//chromedriver.exe\",options=option)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at: 2022-10-26 19:40:42.859102\n",
      "\n",
      "1995\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "1996\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "1997\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "1998\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "1999\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "2000\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2001\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2002\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2003\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2004\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2005\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n",
      "2006\n",
      "('12', '31')\n",
      "Soup found! <class 'bs4.BeautifulSoup'>\n",
      "No duplicates on this page\n"
     ]
    }
   ],
   "source": [
    "get_all_text('gal767', os.getenv('eid_password'), gen_searches(), first_login=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90117093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.find('div', {'id': 'headlines'}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3570200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hospitals():\n",
    "    \n",
    "    url = 'https://www.google.com/'   \n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_experimental_option(\"debuggerAddress\", \"localhost:9222\")\n",
    "    driver = webdriver.Chrome(executable_path = \"C://Users//galon//cd_secure//chromedriver.exe\",options=option)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    driver.set_page_load_timeout(40)\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_hospitals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38cdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
