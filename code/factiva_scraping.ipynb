{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d25c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException, \n",
    "    NoSuchElementException, \n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pickle, json, time, os\n",
    "import regex as re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_searches():\n",
    "    \n",
    "    sources = ['rst=sfusat', 'rst=sfwsj', 'rst=sfnyt', 'rst=sfglob', '(rst=ftft or rst=ftcom)']\n",
    "    companies = ['applc']\n",
    "\n",
    "    return [f'{source} and fds={company}' for source in sources for company in companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6ac322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_search(driver, wait, dates, year, search):\n",
    "\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//select[@name=\"dr\"]'))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//option[@value=\"Custom\"]'))).click()\n",
    "    driver.find_element(By.ID, 'frm').clear()\n",
    "    driver.find_element(By.ID, 'frm').send_keys('01')\n",
    "    driver.find_element(By.ID, 'frd').clear()\n",
    "    driver.find_element(By.ID, 'frd').send_keys('01')\n",
    "    driver.find_element(By.ID, 'fry').clear()\n",
    "    driver.find_element(By.ID, 'fry').send_keys(year)\n",
    "    driver.find_element(By.ID, 'tom').clear()\n",
    "    driver.find_element(By.ID, 'tom').send_keys(dates[0])\n",
    "    driver.find_element(By.ID, 'tod').clear()\n",
    "    driver.find_element(By.ID, 'tod').send_keys(dates[1])\n",
    "    driver.find_element(By.ID, 'toy').clear()\n",
    "    driver.find_element(By.ID, 'toy').send_keys(year)\n",
    "    driver.find_element(By.XPATH, '//select[@name=\"isrd\"]').click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//option[@value=\"High\"]'))).click()\n",
    "    search_box = driver.find_element(By.XPATH, '//textarea[@name=\"ftx\"]')\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(search)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//div[@class=\"pillNoMenu\"]').click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    search_box.send_keys(Keys.ENTER)\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//span[@data-channel=\"Dowjones\"]')))\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555dc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_loop(driver, wait):\n",
    "    \n",
    "    attempts = 0\n",
    "    while attempts < 5:\n",
    "        try:\n",
    "            wait.until(EC.visibility_of_element_located((By.XPATH, '//a[@class=\"nextItem\"]'))).click()\n",
    "            wait.until(EC.visibility_of_element_located((By.XPATH, '//img[@src=\"../img/listmanager/progress.gif\"]')))\n",
    "            wait.until(EC.invisibility_of_element_located((By.XPATH, '//img[@src=\"../img/listmanager/progress.gif\"]')))\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            attempts += 1\n",
    "        except ElementClickInterceptedException:\n",
    "            attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a011bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_info(soup, counter):\n",
    "    \n",
    "    article_links = []\n",
    "    map_dict = {\n",
    "        'January': '1',\n",
    "        'February': '1',\n",
    "        'March': '1',\n",
    "        'April': '2',\n",
    "        'May': '2',\n",
    "        'June': '2',\n",
    "        'July': '3',\n",
    "        'August': '3',\n",
    "        'September': '3',\n",
    "        'October': '4',\n",
    "        'November': '4',\n",
    "        'December': '4',\n",
    "    }\n",
    "    \n",
    "    for headline in soup.find_all('tr', {'class': 'headline'}):\n",
    "            \n",
    "        article_links.append(headline.find('a').get('href'))\n",
    "        sub_list = sum([subtitle.split(' ') for subtitle in headline.find('div').text.split(',') if len(re.findall('[0-9]+', subtitle)) > 0], [])\n",
    "        month = ''.join(set(sub_list) & set(map_dict.keys()))\n",
    "        counter[map_dict[month]] += 1\n",
    "        \n",
    "    return counter, article_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b6de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(eid_username, eid_password, search_function, first_login):\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument explanations:\n",
    "    \n",
    "    1. eid_username\n",
    "    \n",
    "        - Should be your UT EID username that you use to login to Canvas\n",
    "    \n",
    "    2. eid_password\n",
    "    \n",
    "        - Should be your password to login to Canvas\n",
    "        - I recommend you putting the password in a .env file and using the following format for the password argument:\n",
    "        os.getenv(\"password_variable_name\") where password variable name is a name you choose to define your password variable\n",
    "        inside of the .env folder.\n",
    "        \n",
    "    3. search_function\n",
    "        \n",
    "        - Is defined above by inputting a dataframe filled with company codes\n",
    "        \n",
    "    4. first_login\n",
    "    \n",
    "        - A boolean that is True if your browser has not yet logged into Factiva and False otherwise. Every time you\n",
    "        reopen the browser, you need to set this to True because closing the browser deletes some of your session cookies. Afterwards, you\n",
    "        may return to the main search page by setting this value to false and rerunning the function.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://guides.lib.utexas.edu/db/144'\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_experimental_option(\"debuggerAddress\", \"localhost:9222\")\n",
    "    driver = webdriver.Chrome(executable_path = \"C://Users//galon//cd_secure//chromedriver.exe\",options=option)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.set_page_load_timeout(20)\n",
    "    driver.get(url)\n",
    "    \n",
    "    if first_login == True:\n",
    "\n",
    "        wait.until(EC.element_to_be_clickable((By.ID, 'username')))\n",
    "        driver.find_element(By.ID, 'username').send_keys(eid_username)\n",
    "        driver.find_element(By.XPATH, '//input[@id=\"password\"]').send_keys(eid_password)    \n",
    "        driver.find_element(By.XPATH, \"//input[@value='Sign in']\").click()\n",
    "        try:\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='trust-browser-button']\"))).click()\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print('Duo cookies still valid; proceeding to search page...')   \n",
    "    print(f'\\nStarting at: {datetime.now()}\\n')\n",
    "    searches = search_function\n",
    "    df = pd.DataFrame.from_dict({'year': [], 'quarter': [], 'count': []})\n",
    "    \n",
    "    for search in searches:\n",
    "        \n",
    "        pub_code = search.split('and')[0].strip()\n",
    "        co_code = search.split('fds=')[-1]\n",
    "        for year in range(1995, 2021):\n",
    "            duplicates = 0\n",
    "            counter = {'1': 0, '2': 0, '3': 0, '4': 0}            \n",
    "            if year < 2020:\n",
    "                dates = ('12', '31')\n",
    "            else:\n",
    "                dates = ('06', '30')\n",
    "            enter_search(driver, wait, dates, year, search)\n",
    "            while year:\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                if soup.find('tr', {'class': 'headline'}) == None:\n",
    "                    wait.until(EC.element_to_be_clickable((By.ID, 'btnModifySearch'))).click()\n",
    "                    print(f'year: {year}\\nNo duplicates counted')\n",
    "                    break                    \n",
    "                else:\n",
    "                    counter, article_links = get_page_info(soup, counter)\n",
    "                    duplicates += int(soup.find('span', {'id': 'dedupSummary'}).text.split(':')[1].strip())\n",
    "                    if soup.find('a', {'class', 'nextItem'}) !=  None:\n",
    "                        next_loop(driver, wait)\n",
    "                    else:\n",
    "                        results_bar = soup.find('span', {'class': 'resultsBar'}).text.split()\n",
    "                        total = re.sub(',','',str(results_bar[3]))\n",
    "                        ttotal = re.sub(',','',str(results_bar[5]))\n",
    "                        if (int(ttotal)-duplicates) != int(total):\n",
    "                            return 'Did not count duplicates properly; adjust sleep time'\n",
    "                        else:\n",
    "                            print(f'year: {year}\\nDuplicates are equal')\n",
    "                            wait.until(EC.element_to_be_clickable((By.ID, 'btnModifySearch'))).click()\n",
    "                            break\n",
    "            df = pd.concat([df, pd.DataFrame.from_dict(\n",
    "                {\n",
    "                        'year': [year, year, year, year],\n",
    "                        'quarter': list(counter.keys()),\n",
    "                        'count': list(counter.values()),\n",
    "                        'company_code': [co_code, co_code, co_code, co_code],\n",
    "                        'pub_code': [pub_code,pub_code,pub_code,pub_code,]\n",
    "                }\n",
    "            )])\n",
    "    print(f'Done!\\n{datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dbc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galon\\AppData\\Local\\Temp\\ipykernel_22396\\3540203193.py:32: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"C://Users//galon//cd_secure//chromedriver.exe\",options=option)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at: 2022-10-27 00:52:59.856936\n",
      "\n",
      "year: 1995\n",
      "No duplicates counted\n",
      "year: 1996\n",
      "Duplicates are equal\n",
      "year: 1997\n",
      "Duplicates are equal\n",
      "year: 1998\n",
      "Duplicates are equal\n",
      "year: 1999\n",
      "No duplicates counted\n",
      "year: 2000\n",
      "Duplicates are equal\n",
      "year: 2001\n",
      "Duplicates are equal\n",
      "year: 2002\n",
      "Duplicates are equal\n",
      "year: 2003\n",
      "Duplicates are equal\n",
      "year: 2004\n",
      "Duplicates are equal\n",
      "year: 2005\n",
      "Duplicates are equal\n",
      "year: 2006\n",
      "Duplicates are equal\n",
      "year: 2007\n",
      "Duplicates are equal\n",
      "year: 2008\n",
      "Duplicates are equal\n",
      "year: 2009\n",
      "Duplicates are equal\n",
      "year: 2010\n",
      "Duplicates are equal\n",
      "year: 2011\n",
      "Duplicates are equal\n",
      "year: 2012\n",
      "Duplicates are equal\n",
      "year: 2013\n",
      "Duplicates are equal\n",
      "year: 2014\n",
      "Duplicates are equal\n"
     ]
    }
   ],
   "source": [
    "get_all_text('gal767', os.getenv('eid_password'), gen_searches(), first_login=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38cdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
