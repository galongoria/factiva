{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6cb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os, json, pickle, time\n",
    "import regex as re\n",
    "from bot import set_driver, open_page, get_href_page, check_page\n",
    "from parse import get_article_info\n",
    "import pandas as pd\n",
    "\n",
    "output_name = \"test\"\n",
    "\n",
    "#input_company_file = \"STEP4_Factiva_company_list_7551_7600_sector_Haokun Zhang.csv\"\n",
    "\n",
    "ut_eid = \"hz7297\"\n",
    "\n",
    "eid_password = os.getenv('eid_password')\n",
    "\n",
    "driver_path = \"C://Users//Haokun Zhang//chromedriver//chromedriver.exe\"\n",
    "\n",
    "ARTICLE_DIR = os.path.join('..//data', 'article_hrefs', 'test')\n",
    "\n",
    "os.makedirs(ARTICLE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc98148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_searches():\n",
    "    \n",
    "    try:\n",
    "        with open('step5_searches.pickle', 'rb') as file:\n",
    "            articles = pickle.load(file)\n",
    "            if len(articles) == 0:\n",
    "                print('Create a new pickle to manage searches; current list has been exhausted.')\n",
    "    except FileNotFoundError:\n",
    "        articles = {}\n",
    "        for file_name in os.listdir(ARTICLE_DIR):\n",
    "            l = []\n",
    "            with open(os.path.join(os.path.join(ARTICLE_DIR, file_name))) as file:\n",
    "                href_list =  [t for t in re.sub('\\n','',file.read()).split(r'\"') if len(re.findall('\\w+', t)) > 0]\n",
    "                for href in href_list:\n",
    "                    l.append(f\"https://global-factiva-com.ezproxy.lib.utexas.edu/{href.split('&')[0].split('../')[1]}\")\n",
    "            articles[file_name.split('.')[0]] = l\n",
    "    return articles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23de25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_article_list(driver, wait, article_list, name):\n",
    "    \n",
    "    temp_list = []\n",
    "    name_list = name.split('_')\n",
    "    for href in article_list:\n",
    "        temp_dict = {'company_code': name_list[0], 'news_code': name_list[1], 'date': name_list[2]}\n",
    "        get_href_page(driver, wait, href)\n",
    "        check_page(driver, wait, href)\n",
    "        temp_list.append(get_article_info(driver.page_source, temp_dict))\n",
    "        time.sleep(4)\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932535a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(eid_username, eid_password, path):\n",
    "    \n",
    "    results = []\n",
    "    searches = gen_searches()\n",
    "    searches_pickle = searches.copy()\n",
    "    driver, wait = set_driver(path)\n",
    "    open_page(driver, wait, eid_username, eid_password)\n",
    "    \n",
    "    for name, article_list in searches.items():\n",
    "        for i, (key, item) in enumerate('step5_searches.pickle'):\n",
    "            if item % 10 == 0:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        temp_list = search_article_list(driver, wait, article_list, name)\n",
    "        if temp_list != None:\n",
    "            results += temp_list\n",
    "            print(results)\n",
    "        try:\n",
    "            searches_pickle.pop(name)\n",
    "            with open('step5_searches.pickle', 'wb') as file:\n",
    "                pickle.dump(searches_pickle, file)\n",
    "            with open('dict_list.pickle', 'wb') as file:\n",
    "                pickle.dump(results, file)\n",
    "        except:\n",
    "            return 'Error when saving'\n",
    "        \n",
    "    pd.DataFrame.from_dict(results).to_csv('article_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3ced16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a new pickle to manage searches; current list has been exhausted.\n"
     ]
    }
   ],
   "source": [
    "get_text(ut_eid, eid_password, driver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d01743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe813d33fb720599d9aada66a4818fd948ad502b51cb82be4fab848c4b8987ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
